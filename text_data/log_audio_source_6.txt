тема моей работы разработка модуля анализа аудиозаписи для оценки качества публичных выступлений

актуальность работы заключается в предоставлении студентам молодым преподавателям и учёным возможность анализировать записи тренировок своих выступлений для последующего улучшения их качества
что является затруднительным для самостоятельного выполнения
целью является разработать модуль анализа аудиозаписей публичных выступлений
для достижения цели было поставлено пять задач
это исследовать существующие подходы к распознавания эмоций по аудио сформулировать требования к решению
разработать модель для распознавания эмоций
на основе разработанной модели разрботать сервис 
с возможностью интеграции со сторонними приложениями и демонстрационный клиент для него а также проанализировать полученное решение

для осуществления анализа был выбран подход на основе распознавания эмоций аудиозаписи так это позволят проанализировать выстепление именно с точки зрения качества исполнения а не качества его текст а чего можно было бы достичь например с помощью анализа на основе обработки естественных
языков
в связи с этим были рассмотрены четыре подхода к распознаванию эмоций по аудио это искусственная нейронная сеть метод опорных векторов а также модификации двух предыдущих методов с предварительной кластеризацией
сравнивалось по трём критериям это точность распознавания наличие возможности классификации и сложность практического применения
в результате сравнения был выбран подход на
основе искусственной нейронной сети так как он превосходит остальные подходы по совокупности
трёх критериев

были сформулированы требования к решению
решением будет представлять себя клиент и сервер он же модуль сервер должен иметь API для выполнения анализа аудиозаписи а также быть предназначенным для возможности интеграции со сторонними приложениями и сервисами
и иметь механизм быстрого развёртывания клиент же должен иметь возможность загрузки
предзаписанной записи выступления
а также возможность записать аудио прямо на клиенте
а в ответ клиент должен отображать результаты анализа а именно интерактивный график зависимости эмоций от времени и метрики на основе этих эмоций
для обучения

использовалось три набора данных на английском языке
как можно увидеть из таблицы сравнения у двух из них отсутствуют эмоции спокойствие
поэтому она не используется в дальнейшем для распознавания
всего без учёта эмоций спокойствие
использовалось четыре тысячи пятьсот двадцать восемь записи
двадцати восьми актёров
в качестве признаков используются и мел частотные кепстральные коэффициенты их графическое представление для некоторых задач представлено на изображении внизу слайдах
в данной работе выделяют сорок коэффициентов для каждого фрейма записи и затем для формирования входных данных нейронной сети вычисляется среднее значение коэффициентов для каждого из сорока уровней
в итоге получается вектор из сорока значений

модель для распознавания эмоций представляет из себя свёрточную нейронную сеть состоящую из семи слоёв
на входной слой подаётся сорок значений
на выходном слое получаем вероятность принадлежности записи
ко всем семи эмоциям
используются два слоя с функциями активации relu и софт макс также используется слой сброса для предотвращения переобучения
сеть построена с помощью библиотеки keras и сохранена в формате tensorflow saved module
что позволяет использовать её во множестве языков программирования или развёртывать
как самостоятельный сервер для классификации

разработанное решение имеет клиент серверную архитектуру сервер имеют api для получения анализа аудиозаписи
клиент общается с сервером посредством http запросов
сервер имеет возможность быстрого развёртывания с помощью докер контейнера
также предусмотрена возможность переориентирования решения на другой язык например на русский при наличии подходящего набора данных

последовательность обработки аудиозаписи на сервере состоит из следующих шагов первый конвертация полученного аудио файлов формат wav если он имеет другой формат
далее выделение признаков то есть мел частотных кепстральных коэффициентов
далее полученные признаки разбиваются на части чтобы каждая часть соответствала трём секундам записи
затем вычисляется среднее значение для каждого уровня коэффициентов
далее происходит предсказание эмоции на основе входных данных полученных на предыдущем шаге
вычисление метрик на основе предсказаний
после этого полученные данные отправляются обратно на клиент

на данном слайде представлены фрагменты демонстрационного веб приложения
в нём имеется возможность загрузить предзаписанную тренировку выступления а также сделать запись прямо в нём
результаты анализа отображаются в виде интерактивного графика зависимости эмоции от времени и таблицы с метрикой для каждой эмоции

итоговая точность полученной модели составила восемьдесят пять целых девять десятых процента на записях из исходного набора данных
в таблице представлены метрики точность полнота и мера для каждого класса
из таблицы видно что точность для всех классов довольно высока минимальное значение это семьдесят пять процентов
но классы страх и разочарование распознаются значительно хуже остальных
и также эти классы имеют большее число ложноположительных результатов чем остальные

в заключение стоит сказать что все поставленные задачи были выполнены в полной мере и в результате был разработан модуль анализа аудиозаписей которые позволяют проанализировать публичные выступления с точки зрения выражения эмоций
также для него был разработан демонстрационный клиент
для дальнейших исследований было выделено два основных направления первое из них совмещение разработанного решения с анализом самого текста выступления
а именно метрик из области обработки естественного языка таких как тональность текста и другие и второе направление это выявление зависимости качества выступления от изменения эмоций в процессе выступления

на данном слайде представлена ссылка на репозиторий проекта с исходным кодом опубликованный докер образ сервера и развёрнутая демонстрационное приложение
кьюар код также ведёт на развёрнутое приложение спасибо за внимание


